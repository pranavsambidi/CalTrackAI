{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3293bd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a92a1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_CSV = \"../data/clean/train_cleaned.csv\"\n",
    "TEST_CSV = \"../data/clean/test_cleaned.csv\"\n",
    "IMAGE_DIR = \"../data/raw/food-101/images/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5988ff07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        image_name    label\n",
      "0  churros/1004234  churros\n",
      "1  churros/1004234  churros\n",
      "2  churros/1013460  churros\n",
      "3  churros/1013460  churros\n",
      "4  churros/1016791  churros\n",
      "        image_name    label\n",
      "0  churros/1061830  churros\n",
      "1  churros/1064042  churros\n",
      "2  churros/1074903  churros\n",
      "3  churros/1085259  churros\n",
      "4  churros/1097261  churros\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(TRAIN_CSV)[[\"image_name\", \"label\"]]\n",
    "test_df = pd.read_csv(TEST_CSV)[[\"image_name\", \"label\"]]\n",
    "\n",
    "print(train_df.head())\n",
    "print(test_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da42359c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_path(x):\n",
    "    return os.path.join(IMAGE_DIR, x + \".jpg\")\n",
    "\n",
    "train_df[\"image_path\"] = train_df[\"image_name\"].apply(make_path)\n",
    "test_df[\"image_path\"] = test_df[\"image_name\"].apply(make_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84f9da53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: 101\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "train_df[\"label_encoded\"] = label_encoder.fit_transform(train_df[\"label\"])\n",
    "test_df[\"label_encoded\"] = label_encoder.transform(test_df[\"label\"])\n",
    "\n",
    "num_classes = len(label_encoder.classes_)\n",
    "print(\"Classes:\", num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b6f26cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"../data/clean/label_map.json\", \"w\") as f:\n",
    "    json.dump({c: int(i) for i, c in enumerate(label_encoder.classes_)}, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4eda3693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 83250 validated image filenames.\n",
      "Found 25250 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_gen = train_datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    x_col=\"image_path\",\n",
    "    y_col=\"label_encoded\",\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"raw\",     \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_gen = val_datagen.flow_from_dataframe(\n",
    "    test_df,\n",
    "    x_col=\"image_path\",\n",
    "    y_col=\"label_encoded\",\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"raw\",     \n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51736600",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "x = base.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "preds = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=base.input, outputs=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10835d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base.layers:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e22dd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(1e-3),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39ed9330",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    \"../data/clean/resnet50_food101_head.keras\",\n",
    "    monitor=\"val_accuracy\",\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=2,\n",
    "    factor=0.2,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early = EarlyStopping(\n",
    "    patience=4,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "csv_logger = CSVLogger(\"../data/clean/resnet50_training_log.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66f23709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "\u001b[1m2602/2602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2577 - loss: 3.1387\n",
      "Epoch 1: val_accuracy improved from -inf to 0.53493, saving model to ../data/clean/resnet50_food101_head.keras\n",
      "\u001b[1m2602/2602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4218s\u001b[0m 2s/step - accuracy: 0.2577 - loss: 3.1385 - val_accuracy: 0.5349 - val_loss: 1.7740 - learning_rate: 0.0010\n",
      "Epoch 2/8\n",
      "\u001b[1m2602/2602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3857 - loss: 2.4728\n",
      "Epoch 2: val_accuracy improved from 0.53493 to 0.55085, saving model to ../data/clean/resnet50_food101_head.keras\n",
      "\u001b[1m2602/2602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4018s\u001b[0m 2s/step - accuracy: 0.3857 - loss: 2.4728 - val_accuracy: 0.5509 - val_loss: 1.7155 - learning_rate: 0.0010\n",
      "Epoch 3/8\n",
      "\u001b[1m2602/2602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4067 - loss: 2.3649\n",
      "Epoch 3: val_accuracy improved from 0.55085 to 0.56131, saving model to ../data/clean/resnet50_food101_head.keras\n",
      "\u001b[1m2602/2602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4094s\u001b[0m 2s/step - accuracy: 0.4067 - loss: 2.3649 - val_accuracy: 0.5613 - val_loss: 1.6408 - learning_rate: 0.0010\n",
      "Epoch 4/8\n",
      "\u001b[1m2602/2602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4227 - loss: 2.3056\n",
      "Epoch 4: val_accuracy improved from 0.56131 to 0.58111, saving model to ../data/clean/resnet50_food101_head.keras\n",
      "\u001b[1m2602/2602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3969s\u001b[0m 2s/step - accuracy: 0.4227 - loss: 2.3056 - val_accuracy: 0.5811 - val_loss: 1.5859 - learning_rate: 0.0010\n",
      "Epoch 5/8\n",
      "\u001b[1m2602/2602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4384 - loss: 2.2474\n",
      "Epoch 5: val_accuracy improved from 0.58111 to 0.58879, saving model to ../data/clean/resnet50_food101_head.keras\n",
      "\u001b[1m2602/2602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3987s\u001b[0m 2s/step - accuracy: 0.4384 - loss: 2.2474 - val_accuracy: 0.5888 - val_loss: 1.5579 - learning_rate: 0.0010\n",
      "Epoch 6/8\n",
      "\u001b[1m2602/2602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4456 - loss: 2.2342\n",
      "Epoch 6: val_accuracy improved from 0.58879 to 0.58994, saving model to ../data/clean/resnet50_food101_head.keras\n",
      "\u001b[1m2602/2602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4173s\u001b[0m 2s/step - accuracy: 0.4456 - loss: 2.2342 - val_accuracy: 0.5899 - val_loss: 1.5634 - learning_rate: 0.0010\n",
      "Epoch 7/8\n",
      "\u001b[1m2602/2602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4529 - loss: 2.1926\n",
      "Epoch 7: val_accuracy improved from 0.58994 to 0.59564, saving model to ../data/clean/resnet50_food101_head.keras\n",
      "\u001b[1m2602/2602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4160s\u001b[0m 2s/step - accuracy: 0.4529 - loss: 2.1926 - val_accuracy: 0.5956 - val_loss: 1.5333 - learning_rate: 0.0010\n",
      "Epoch 8/8\n",
      "\u001b[1m2602/2602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4614 - loss: 2.1601\n",
      "Epoch 8: val_accuracy did not improve from 0.59564\n",
      "\u001b[1m2602/2602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4302s\u001b[0m 2s/step - accuracy: 0.4614 - loss: 2.1601 - val_accuracy: 0.5939 - val_loss: 1.5565 - learning_rate: 0.0010\n",
      "Restoring model weights from the end of the best epoch: 7.\n"
     ]
    }
   ],
   "source": [
    "history_head = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=8,\n",
    "    callbacks=[checkpoint, reduce_lr, early, csv_logger]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5cb99ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base.layers[-50:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(1e-5),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41b09fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2602/2602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4288 - loss: 2.3255\n",
      "Epoch 1: val_accuracy improved from 0.59564 to 0.64412, saving model to ../data/clean/resnet50_food101_head.keras\n",
      "\u001b[1m2602/2602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6136s\u001b[0m 2s/step - accuracy: 0.4288 - loss: 2.3254 - val_accuracy: 0.6441 - val_loss: 1.3493 - learning_rate: 1.0000e-05\n",
      "Epoch 2/10\n",
      "\u001b[1m2602/2602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5308 - loss: 1.8298\n",
      "Epoch 2: val_accuracy improved from 0.64412 to 0.67184, saving model to ../data/clean/resnet50_food101_head.keras\n",
      "\u001b[1m2602/2602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6385s\u001b[0m 2s/step - accuracy: 0.5308 - loss: 1.8298 - val_accuracy: 0.6718 - val_loss: 1.2368 - learning_rate: 1.0000e-05\n",
      "Epoch 3/10\n",
      "\u001b[1m2602/2602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5660 - loss: 1.6730\n",
      "Epoch 3: val_accuracy improved from 0.67184 to 0.69263, saving model to ../data/clean/resnet50_food101_head.keras\n",
      "\u001b[1m2602/2602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6596s\u001b[0m 3s/step - accuracy: 0.5660 - loss: 1.6730 - val_accuracy: 0.6926 - val_loss: 1.1511 - learning_rate: 1.0000e-05\n",
      "Epoch 4/10\n",
      "\u001b[1m2602/2602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5913 - loss: 1.5766\n",
      "Epoch 4: val_accuracy improved from 0.69263 to 0.70020, saving model to ../data/clean/resnet50_food101_head.keras\n",
      "\u001b[1m2602/2602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7304s\u001b[0m 3s/step - accuracy: 0.5913 - loss: 1.5766 - val_accuracy: 0.7002 - val_loss: 1.1234 - learning_rate: 1.0000e-05\n",
      "Epoch 5/10\n",
      "\u001b[1m2602/2602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6112 - loss: 1.4773\n",
      "Epoch 5: val_accuracy improved from 0.70020 to 0.70954, saving model to ../data/clean/resnet50_food101_head.keras\n",
      "\u001b[1m2602/2602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6981s\u001b[0m 3s/step - accuracy: 0.6112 - loss: 1.4773 - val_accuracy: 0.7095 - val_loss: 1.0827 - learning_rate: 1.0000e-05\n",
      "Epoch 6/10\n",
      "\u001b[1m2602/2602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6322 - loss: 1.3992\n",
      "Epoch 6: val_accuracy improved from 0.70954 to 0.71897, saving model to ../data/clean/resnet50_food101_head.keras\n",
      "\u001b[1m2602/2602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6690s\u001b[0m 3s/step - accuracy: 0.6322 - loss: 1.3992 - val_accuracy: 0.7190 - val_loss: 1.0665 - learning_rate: 1.0000e-05\n",
      "Epoch 7/10\n",
      "\u001b[1m2602/2602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6430 - loss: 1.3458\n",
      "Epoch 7: val_accuracy improved from 0.71897 to 0.72653, saving model to ../data/clean/resnet50_food101_head.keras\n",
      "\u001b[1m2602/2602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6976s\u001b[0m 3s/step - accuracy: 0.6430 - loss: 1.3458 - val_accuracy: 0.7265 - val_loss: 1.0207 - learning_rate: 1.0000e-05\n",
      "Epoch 8/10\n",
      "\u001b[1m2602/2602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6574 - loss: 1.2809\n",
      "Epoch 8: val_accuracy improved from 0.72653 to 0.73576, saving model to ../data/clean/resnet50_food101_head.keras\n",
      "\u001b[1m2602/2602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7132s\u001b[0m 3s/step - accuracy: 0.6574 - loss: 1.2809 - val_accuracy: 0.7358 - val_loss: 1.0050 - learning_rate: 1.0000e-05\n",
      "Epoch 9/10\n",
      "\u001b[1m2602/2602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6719 - loss: 1.2177\n",
      "Epoch 9: val_accuracy did not improve from 0.73576\n",
      "\u001b[1m2602/2602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6334s\u001b[0m 2s/step - accuracy: 0.6719 - loss: 1.2177 - val_accuracy: 0.7356 - val_loss: 0.9924 - learning_rate: 1.0000e-05\n",
      "Epoch 10/10\n",
      "\u001b[1m2602/2602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6844 - loss: 1.1727\n",
      "Epoch 10: val_accuracy improved from 0.73576 to 0.74325, saving model to ../data/clean/resnet50_food101_head.keras\n",
      "\u001b[1m2602/2602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6301s\u001b[0m 2s/step - accuracy: 0.6844 - loss: 1.1727 - val_accuracy: 0.7432 - val_loss: 0.9769 - learning_rate: 1.0000e-05\n",
      "Restoring model weights from the end of the best epoch: 10.\n"
     ]
    }
   ],
   "source": [
    "history_fine = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=10,\n",
    "    callbacks=[checkpoint, reduce_lr, early, csv_logger]\n",
    ")\n",
    "\n",
    "model.save(\"../data/clean/resnet50_food101_final.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0e885e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "model = tf.keras.models.load_model(\"../data/clean/resnet50_food101_final.keras\")\n",
    "\n",
    "with open(\"../data/clean/label_map.json\") as f:\n",
    "    label_map = json.load(f)\n",
    "\n",
    "inv_map = {v: k for k, v in label_map.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "207c1bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_food(img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_arr = image.img_to_array(img)\n",
    "    img_arr = np.expand_dims(img_arr, axis=0)\n",
    "    img_arr = preprocess_input(img_arr)\n",
    "\n",
    "    preds = model.predict(img_arr)\n",
    "    idx = np.argmax(preds)\n",
    "\n",
    "    return inv_map[idx], preds[0][idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4e1eb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "usda_df = pd.read_csv(\"../data/raw/usda_food_data.csv\")\n",
    "\n",
    "from rapidfuzz import process\n",
    "\n",
    "def get_nutrition(food_label):\n",
    "    descs = usda_df[\"description\"].astype(str).tolist()\n",
    "    match, score = process.extractOne(food_label.replace(\"_\", \" \"), descs)\n",
    "    row = usda_df[usda_df[\"description\"] == match]\n",
    "    if len(row):\n",
    "        return row.iloc[0]\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "563b817e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in .keras format\n",
      "Model also saved in .h5 format\n",
      "Model weights saved separately\n"
     ]
    }
   ],
   "source": [
    "model.save(\"../data/clean/resnet50_food101_finetuned.keras\")\n",
    "print(\"Model saved in .keras format\")\n",
    "\n",
    "model.save(\"../data/clean/resnet50_food101_finetuned.h5\")\n",
    "print(\"Model also saved in .h5 format\")\n",
    "\n",
    "model.save_weights(\"../data/clean/resnet50_food101.weights.h5\")\n",
    "print(\"Model weights saved separately\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
