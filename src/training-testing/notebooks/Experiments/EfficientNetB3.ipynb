{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d9975b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.17.0\n",
      "Mixed precision: <DTypePolicy \"float32\">\n",
      "GPU available: []\n"
     ]
    }
   ],
   "source": [
    "import os, json, math, random, pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import (ModelCheckpoint, ReduceLROnPlateau,\n",
    "                                        EarlyStopping, CSVLogger)\n",
    "from tensorflow.keras.metrics import TopKCategoricalAccuracy\n",
    "from tensorflow.keras.applications import efficientnet\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Optional mixed precision if you have a GPU (comment out if it causes issues on CPU-only)\n",
    "# try:\n",
    "#     tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "# except Exception:\n",
    "#     pass\n",
    "\n",
    "SEED = 42\n",
    "IMG_SIZE = 300   # EfficientNetB3 default\n",
    "BATCH_SIZE = 24  # adjust down if you hit OOM\n",
    "VAL_FRACTION = 0.1\n",
    "EPOCHS_HEAD = 8\n",
    "EPOCHS_FT = 15\n",
    "DATA_ROOT = \"../data/raw/food-101/images\"\n",
    "TRAIN_CSV = \"../data/clean/train_cleaned.csv\"\n",
    "TEST_CSV  = \"../data/clean/test_cleaned.csv\"\n",
    "LABEL_MAP_JSON = \"../data/clean/label_map.json\"\n",
    "MODEL_HEAD = \"../data/clean/effb3_head.keras\"\n",
    "MODEL_FT   = \"../data/clean/effb3_finetuned.keras\"\n",
    "CSV_LOG    = \"../data/clean/training_log.csv\"\n",
    "\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"Mixed precision:\", tf.keras.mixed_precision.global_policy())\n",
    "print(\"GPU available:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05d8101a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 83250  | Test rows: 25250\n",
      "Missing train images: 0 | Missing test images: 0\n",
      "Num classes: 101\n",
      "Saved label_map to: ../data/clean/label_map.json\n",
      "Sample label_map items: [('apple_pie', 0), ('baby_back_ribs', 1), ('baklava', 2), ('beef_carpaccio', 3), ('beef_tartare', 4), ('beet_salad', 5), ('beignets', 6), ('bibimbap', 7)]\n"
     ]
    }
   ],
   "source": [
    "# Load CSVs\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "test_df  = pd.read_csv(TEST_CSV)\n",
    "\n",
    "# Build absolute image paths from image_name\n",
    "def make_path(row):\n",
    "    # image_name already like \"label/12345\" (without .jpg)\n",
    "    return os.path.join(DATA_ROOT, f\"{row['image_name']}.jpg\")\n",
    "\n",
    "train_df[\"image_path\"] = train_df.apply(make_path, axis=1)\n",
    "test_df[\"image_path\"]  = test_df.apply(make_path, axis=1)\n",
    "\n",
    "# Quick sanity checks\n",
    "print(\"Train rows:\", len(train_df), \" | Test rows:\", len(test_df))\n",
    "missing_train = (~train_df[\"image_path\"].apply(os.path.exists)).sum()\n",
    "missing_test  = (~test_df[\"image_path\"].apply(os.path.exists)).sum()\n",
    "print(f\"Missing train images: {missing_train} | Missing test images: {missing_test}\")\n",
    "\n",
    "# Filter out any missing files (should be zero ideally)\n",
    "if missing_train > 0:\n",
    "    train_df = train_df[train_df[\"image_path\"].apply(os.path.exists)].reset_index(drop=True)\n",
    "if missing_test > 0:\n",
    "    test_df = test_df[test_df[\"image_path\"].apply(os.path.exists)].reset_index(drop=True)\n",
    "\n",
    "# Encode labels from TRAIN ONLY (fit on train labels)\n",
    "le = LabelEncoder()\n",
    "train_df[\"label_idx\"] = le.fit_transform(train_df[\"label\"])\n",
    "num_classes = len(le.classes_)\n",
    "print(\"Num classes:\", num_classes)\n",
    "\n",
    "# Map test labels -> idx (labels should be a subset of training labels)\n",
    "test_df[\"label_idx\"] = le.transform(test_df[\"label\"])\n",
    "label_map = {str(cls): int(idx) for cls, idx in zip(le.classes_, le.transform(le.classes_))}\n",
    "with open(LABEL_MAP_JSON, \"w\") as f:\n",
    "    json.dump(label_map, f)\n",
    "print(\"Saved label_map to:\", LABEL_MAP_JSON)\n",
    "print(\"Sample label_map items:\", list(label_map.items())[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36a2e4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train split: (74925, 14) Val split: (8325, 14)\n",
      "Label distribution (train) top-5:\n",
      " label\n",
      "churros             1350\n",
      "baklava             1350\n",
      "mussels             1350\n",
      "huevos_rancheros    1350\n",
      "tiramisu            1350\n",
      "Name: count, dtype: int64\n",
      "Label distribution (val)   top-5:\n",
      " label\n",
      "churros         150\n",
      "creme_brulee    150\n",
      "mussels         150\n",
      "tiramisu        150\n",
      "falafel         150\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Build Stratified train/val split on the training data\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=VAL_FRACTION, random_state=SEED)\n",
    "train_idx, val_idx = next(sss.split(train_df[\"image_path\"], train_df[\"label_idx\"]))\n",
    "\n",
    "train_df_s = train_df.iloc[train_idx].reset_index(drop=True)\n",
    "val_df_s   = train_df.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "print(\"Train split:\", train_df_s.shape, \"Val split:\", val_df_s.shape)\n",
    "print(\"Label distribution (train) top-5:\\n\", train_df_s[\"label\"].value_counts().head())\n",
    "print(\"Label distribution (val)   top-5:\\n\", val_df_s[\"label\"].value_counts().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5496a731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: (8, 260, 260, 3) (8,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-05 23:42:42.545254: W tensorflow/core/kernels/data/cache_dataset_ops.cc:913] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2025-11-05 23:42:42.547823: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# EfficientNet preprocess\n",
    "preprocess_fn = efficientnet.preprocess_input  # scales to [-1,1]\n",
    "\n",
    "# Keras native augmentation layers (fast, on-GPU)\n",
    "data_augment = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.08),\n",
    "    layers.RandomZoom(0.1),\n",
    "])\n",
    "\n",
    "def decode_resize(path, label_idx, augment=False):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE], antialias=True)\n",
    "    img = preprocess_fn(img)\n",
    "    if augment:\n",
    "        img = data_augment(img)\n",
    "    return img, label_idx\n",
    "\n",
    "def make_ds(df, batch, shuffle=False, augment=False, cache=True):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((df[\"image_path\"].values, df[\"label_idx\"].values))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(min(len(df), 10_000), seed=SEED, reshuffle_each_iteration=True)\n",
    "    ds = ds.map(lambda p, y: decode_resize(p, y, augment=augment), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    if cache:\n",
    "        ds = ds.cache()\n",
    "    ds = ds.batch(batch).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "train_ds = make_ds(train_df_s, BATCH_SIZE, shuffle=True, augment=True)\n",
    "val_ds   = make_ds(val_df_s,   BATCH_SIZE, shuffle=False, augment=False)\n",
    "test_ds  = make_ds(test_df,    BATCH_SIZE, shuffle=False, augment=False)\n",
    "\n",
    "# Peek\n",
    "for x_batch, y_batch in train_ds.take(1):\n",
    "    print(\"Batch:\", x_batch.shape, y_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b678c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example class_weights (first 10): {0: 2.0, 1: 2.0, 2: 1.0, 3: 2.0, 4: 2.0, 5: 2.0, 6: 2.0, 7: 2.0, 8: 2.0, 9: 2.0}\n"
     ]
    }
   ],
   "source": [
    "# Compute class weights (optional but helpful for imbalanced classes)\n",
    "counts = train_df_s[\"label_idx\"].value_counts().sort_index().values\n",
    "max_count = counts.max()\n",
    "class_weights = {i: float(max_count / c) for i, c in enumerate(counts)}\n",
    "print(\"Example class_weights (first 10):\", dict(list(class_weights.items())[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b14743c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Food101_EfficientNetB3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Food101_EfficientNetB3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ efficientnetb3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1536</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">10,783,535</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1536</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1536</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">155,237</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m260\u001b[0m, \u001b[38;5;34m260\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ efficientnetb3 (\u001b[38;5;33mFunctional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m1536\u001b[0m)     │    \u001b[38;5;34m10,783,535\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1536\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1536\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m)            │       \u001b[38;5;34m155,237\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,938,772</span> (41.73 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,938,772\u001b[0m (41.73 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">155,237</span> (606.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m155,237\u001b[0m (606.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,783,535</span> (41.14 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m10,783,535\u001b[0m (41.14 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base = efficientnet.EfficientNetB3(include_top=False, weights=\"imagenet\",\n",
    "                                   input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "base.trainable = False  # freeze\n",
    "\n",
    "inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "x = base(inputs, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.35)(x)\n",
    "# IMPORTANT: in mixed precision, set dtype for the final Dense to float32 for numerical stability\n",
    "outputs = layers.Dense(num_classes, activation=\"softmax\", dtype=\"float32\")(x)\n",
    "model = Model(inputs, outputs, name=\"Food101_EfficientNetB3\")\n",
    "\n",
    "from tensorflow.keras.metrics import SparseTopKCategoricalAccuracy\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-3),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\", SparseTopKCategoricalAccuracy(k=5, name=\"top5\")]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a40ae0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: (8, 260, 260, 3)  y: (8,)  dtype: <dtype: 'int64'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-05 23:42:43.333099: W tensorflow/core/kernels/data/cache_dataset_ops.cc:913] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2025-11-05 23:42:43.343012: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_ds.take(1):\n",
    "    print(\"x:\", x.shape, \" y:\", y.shape, \" dtype:\", y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ccdc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "\u001b[1m4458/9366\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m24:38\u001b[0m 301ms/step - accuracy: 0.3537 - loss: 5.0075 - top5: 0.6158"
     ]
    }
   ],
   "source": [
    "callbacks_head = [\n",
    "    ModelCheckpoint(MODEL_HEAD, monitor=\"val_accuracy\", save_best_only=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2, verbose=1),\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=4, restore_best_weights=True, verbose=1),\n",
    "    CSVLogger(CSV_LOG, append=False)\n",
    "]\n",
    "\n",
    "hist_head = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS_HEAD,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=callbacks_head\n",
    ")\n",
    "\n",
    "model.save(MODEL_HEAD.replace(\".keras\", \"_last.keras\"))\n",
    "print(\"Head training complete. Saved:\", MODEL_HEAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9573f019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze last ~100 layers for fine-tuning (tune this number if needed)\n",
    "for layer in base.layers[-100:]:\n",
    "    if not isinstance(layer, layers.BatchNormalization):\n",
    "        layer.trainable = True\n",
    "\n",
    "# Compile with lower LR\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-5),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\", TopKCategoricalAccuracy(k=5, name=\"top5\")]\n",
    ")\n",
    "\n",
    "callbacks_ft = [\n",
    "    ModelCheckpoint(MODEL_FT, monitor=\"val_accuracy\", save_best_only=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2, verbose=1),\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True, verbose=1),\n",
    "    CSVLogger(CSV_LOG, append=True)\n",
    "]\n",
    "\n",
    "hist_ft = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS_FT,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=callbacks_ft\n",
    ")\n",
    "\n",
    "model.save(MODEL_FT.replace(\".keras\", \"_last.keras\"))\n",
    "print(\"Fine-tuning complete. Saved:\", MODEL_FT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a977b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curves(history_list, keys=(\"accuracy\",\"val_accuracy\")):\n",
    "    plt.figure(figsize=(6,4))\n",
    "    for h in history_list:\n",
    "        plt.plot(h.history[keys[0]], label=f\"train {keys[0]}\")\n",
    "        plt.plot(h.history[keys[1]], label=f\"val {keys[1]}\")\n",
    "    plt.legend(); plt.title(\" / \".join(keys)); plt.xlabel(\"Epoch\"); plt.ylabel(\"Score\"); plt.show()\n",
    "\n",
    "plot_curves([hist_head, hist_ft], (\"accuracy\", \"val_accuracy\"))\n",
    "plot_curves([hist_head, hist_ft], (\"top5\", \"val_top5\"))\n",
    "plot_curves([hist_head, hist_ft], (\"loss\", \"val_loss\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf6399f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = model.evaluate(test_ds, verbose=1)\n",
    "print(\"\\nTest metrics [loss, top1 acc, top5 acc]:\", test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bca577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect preds/targets (may take a few minutes on CPU)\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for xb, yb in test_ds:\n",
    "    logits = model.predict(xb, verbose=0)\n",
    "    y_true.extend(yb.numpy().tolist())\n",
    "    y_pred.extend(np.argmax(logits, axis=1).tolist())\n",
    "\n",
    "print(\"Classes:\", len(le.classes_))\n",
    "print(classification_report(y_true, y_pred, target_names=le.classes_, digits=3)[:2000])  # truncated print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73e0ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pred, labels=list(range(num_classes)))\n",
    "cm_df = pd.DataFrame(cm, index=le.classes_, columns=le.classes_)\n",
    "cm_df.to_csv(\"../data/clean/confusion_matrix.csv\")\n",
    "print(\"Saved confusion_matrix.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edd3d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz import process as rf_process, fuzz as rf_fuzz\n",
    "import re\n",
    "from PIL import Image\n",
    "\n",
    "USDA_CSV = \"../data/raw/usda_food_data.csv\"\n",
    "usda_df = pd.read_csv(USDA_CSV)\n",
    "\n",
    "def normalize_text(s):\n",
    "    s = str(s).lower()\n",
    "    s = re.sub(r'[^a-z\\s]', ' ', s)\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()\n",
    "    return s\n",
    "\n",
    "usda_df[\"normalized_description\"] = usda_df[\"description\"].astype(str).apply(normalize_text)\n",
    "usda_names = usda_df[\"normalized_description\"].tolist()\n",
    "\n",
    "def find_nutrition_for_label(food_label, score_cutoff=75):\n",
    "    q = food_label.replace(\"_\", \" \")\n",
    "    match = rf_process.extractOne(q, usda_names, scorer=rf_fuzz.token_sort_ratio, score_cutoff=score_cutoff)\n",
    "    if match:\n",
    "        hit = usda_df.iloc[usda_df.index[usda_df[\"normalized_description\"] == match[0]][0]]\n",
    "        return {\n",
    "            \"description\": hit.get(\"description\"),\n",
    "            \"calories\": hit.get(\"calories\"),\n",
    "            \"protein\": hit.get(\"protein\"),\n",
    "            \"fat\": hit.get(\"fat\"),\n",
    "            \"carbohydrates\": hit.get(\"carbohydrates\"),\n",
    "            \"score\": match[1]\n",
    "        }\n",
    "    return None\n",
    "\n",
    "# Demo: predict a few random test images\n",
    "samples = random.sample(test_df[\"image_path\"].tolist(), 5)\n",
    "for p in samples:\n",
    "    # Load + predict\n",
    "    img_raw = tf.io.read_file(p)\n",
    "    img = tf.image.decode_jpeg(img_raw, channels=3)\n",
    "    img_resized = tf.image.resize(img, [IMG_SIZE, IMG_SIZE])\n",
    "    img_pp = efficientnet.preprocess_input(img_resized)\n",
    "    pred = model.predict(tf.expand_dims(img_pp, 0), verbose=0)\n",
    "    pred_idx = int(np.argmax(pred, axis=1)[0])\n",
    "    pred_label = le.inverse_transform([pred_idx])[0]\n",
    "\n",
    "    print(f\"\\nImage: {p}\")\n",
    "    print(\"Predicted:\", pred_label)\n",
    "    info = find_nutrition_for_label(pred_label)\n",
    "    if info:\n",
    "        print(\"USDA match:\", info[\"description\"], f\"(score={info['score']})\")\n",
    "        print(f\"Calories: {info['calories']} | Protein: {info['protein']} | Fat: {info['fat']} | Carbs: {info['carbohydrates']}\")\n",
    "    else:\n",
    "        print(\"No close USDA match found.\")\n",
    "\n",
    "    # Show image\n",
    "    try:\n",
    "        display(Image.open(p))\n",
    "    except Exception:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
